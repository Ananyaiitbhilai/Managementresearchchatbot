{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading the XML Document\n",
      "    Reading the XML file from disk with progress bar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading XML: 100%|██████████| 110k/110k [00:00<00:00, 2.79MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Document reading took 0.05 seconds.\n",
      "Step 1 Complete: Loaded 1 document(s) from the XML file in 0.05 seconds.\n",
      "\n",
      "Step 2: Splitting the Document into Smaller Chunks\n",
      "Step 2 Complete: Split the document into 149 chunk(s).\n",
      "\n",
      "Step 3: Generating Embeddings for Each Document Chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 Complete: Embeddings generated for document chunks.\n",
      "\n",
      "Step 4: Building the Vector Store for Similarity-Based Retrieval\n",
      "    Indexing document chunks:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing doc chunks: 100%|██████████| 149/149 [01:37<00:00,  1.53chunk/s]\n",
      "/var/folders/_b/ccc66ybs0m59z0yyhly4_jp80000gn/T/ipykernel_98386/2655779383.py:78: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n",
      "/var/folders/_b/ccc66ybs0m59z0yyhly4_jp80000gn/T/ipykernel_98386/2655779383.py:84: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 Complete: Vector store built and retriever created.\n",
      "\n",
      "Step 5: Setting Up the Retrieval-Augmented Generation QA Chain\n",
      "Step 5 Complete: QA chain is ready.\n",
      "\n",
      "Step 6: Asking a Question and Getting an Answer\n",
      "Step 6 Complete: Query processed.\n",
      "\n",
      "Answer:  CCR5Delta32 may limit HIV spread by decreasing infection rates and reducing viral loads in infected individuals.\n",
      "\n",
      "Relevant Source Documents:\n",
      "{'source': 'try.xml'}\n",
      "{'source': 'try.xml'}\n",
      "{'source': 'try.xml'}\n",
      "{'source': 'try.xml'}\n",
      "{'source': 'try.xml'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import UnstructuredXMLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Set your OpenAI API key (ensure you secure your key appropriately)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<key>\"\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Loading the XML Document with TQDM Progress Bar\n",
    "# ------------------------------\n",
    "print(\"Step 1: Loading the XML Document\")\n",
    "xml_file_path = \"try.xml\" #\"WR_2018_20220207195801_CORE_0030 (1).xml\"  # Update with your XML file path\n",
    "\n",
    "start_total = time.time()\n",
    "\n",
    "print(\"    Reading the XML file from disk with progress bar...\")\n",
    "file_size = os.path.getsize(xml_file_path)\n",
    "document_text = \"\"\n",
    "chunk_size = 1024  # bytes\n",
    "\n",
    "start_load = time.time()\n",
    "with open(xml_file_path, \"r\", encoding=\"utf8\") as f:\n",
    "    with tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=\"Loading XML\") as pbar:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            document_text += chunk\n",
    "            pbar.update(len(chunk))\n",
    "end_load = time.time()\n",
    "\n",
    "print(f\"    Document reading took {end_load - start_load:.2f} seconds.\")\n",
    "\n",
    "documents = [Document(page_content=document_text, metadata={\"source\": xml_file_path})]\n",
    "\n",
    "end_total = time.time()\n",
    "print(f\"Step 1 Complete: Loaded {len(documents)} document(s) from the XML file in {end_total - start_total:.2f} seconds.\\n\")\n",
    "\n",
    "\n",
    "print(\"Step 2: Splitting the Document into Smaller Chunks\")\n",
    "# Using a chunk size of 1000 characters with 200 characters overlap to maintain context\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "doc_chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Step 2 Complete: Split the document into {len(doc_chunks)} chunk(s).\\n\")\n",
    "\n",
    "print(\"Step 3: Generating Embeddings for Each Document Chunk\")\n",
    "# Generate embeddings using OpenAI's embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "print(\"Step 3 Complete: Embeddings generated for document chunks.\\n\")\n",
    "\n",
    "\n",
    "print(\"Step 4: Building the Vector Store for Similarity-Based Retrieval\")\n",
    "# Create an empty Chroma collection by passing the embeddings instance directly.\n",
    "vector_store = Chroma(collection_name=\"xml_docs\", embedding_function=embeddings)\n",
    "\n",
    "print(\"    Indexing document chunks:\")\n",
    "# Iterate over doc_chunks with a tqdm progress bar updating for each chunk.\n",
    "for doc in tqdm(doc_chunks, desc=\"Indexing doc chunks\", unit=\"chunk\"):\n",
    "    vector_store.add_documents([doc])\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "print(\"Step 4 Complete: Vector store built and retriever created.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Step 5: Setting Up the Retrieval-Augmented Generation QA Chain\")\n",
    "# Initialize the LLM with a deterministic response\n",
    "llm = OpenAI(temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
    "print(\"Step 5 Complete: QA chain is ready.\\n\")\n",
    "\n",
    "print(\"Step 6: Asking a Question and Getting an Answer\")\n",
    "\n",
    "query = \"How CCR5Delta32 may limit HIV spread?\"  #ask question\n",
    "result = qa_chain({\"query\": query})\n",
    "print(\"Step 6 Complete: Query processed.\\n\")\n",
    "\n",
    "print(\"Answer:\", result[\"result\"])\n",
    "print(\"\\nRelevant Source Documents:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23d5fa18494b424735fd92ef5e0850dc82214ebc98294842a6c9571a61736055"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('stanford_rag': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
